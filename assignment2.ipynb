{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR3QscOyv4S285+DQ4AUi3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshaya-Raghunath/Scifor/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is the difference between a list and a tuple in Python?"
      ],
      "metadata": {
        "id": "2Er-04Gkwwzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In python both the list and tuple are used to store collections of items, but it has some differences,\n",
        "#LIST:\n",
        "#1.List are mutable, which means we can change their content(add,remove or modify) after they are created\n",
        "#2.Lists are defined using ‘[ ]’\n",
        "#3.It is used to return multiple values from a function because you can easily modify a list within the function and return it.\n",
        "#4.eg:\n",
        "list = [1, 2, 3, 4, 5]\n",
        "list.append(6)\n",
        "list[0] = 10\n",
        "list.remove(2)\n",
        "print(list)\n",
        "\n",
        "#TUPLE:\n",
        "#1.Tuples are immutable, which means once we created a tuple, we cannot change its content\n",
        "#2.Tuples are defined using ‘( )’\n",
        "#3.Tuples are sometimes used to return multiple values as well,\n",
        "#  especially when you want to ensure that the values remain unchanged.\n",
        "#4. eg:\n",
        "person = (\"John Smith\", 30, \"New York\")\n",
        "name, age, city = person\n",
        "print(\"Name:\", name)\n",
        "print(\"Age:\", age)\n",
        "print(\"City:\", city)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20lvuOUwT2x",
        "outputId": "48741028-7b0b-4546-8873-1ce456522e3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 3, 4, 5, 6]\n",
            "Name: John Smith\n",
            "Age: 30\n",
            "City: New York\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.How can you iterate through a list in Python?"
      ],
      "metadata": {
        "id": "zsoNdp9Vzqk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#you can iterate through a list using various methods. Here are some common ways to loop through a list:\n",
        "#1.Using a for Loop:\n",
        "#You can use a for loop to iterate through the elements of a list one by onelist = [1, 2, 3, 4, 5]\n",
        "list = [1, 2, 3, 4, 5]\n",
        "for i in list:\n",
        "    print(i)\n",
        "\n",
        "print(\"*\"*100)\n",
        "\n",
        "#2.Using a while Loop:\n",
        "#You can use a while loop to iterate through a list by manually managing an index.\n",
        "#eg:\n",
        "list1 = [1, 2, 3, 4, 5]\n",
        "index = 0\n",
        "while index < len(list1):\n",
        "    print(list1[index])\n",
        "    index += 1\n",
        "\n",
        "print(\"*\"*100)\n",
        "\n",
        "#3.List Comprehension:\n",
        "#You can use list comprehension to create a new list based on the elements of an existing list.\n",
        "#eg:\n",
        "list2 = [1, 2, 3, 4, 5]\n",
        "squared_list = [i**2 for i in list2]\n",
        "print(squared_list)\n",
        "\n",
        "print(\"*\"*100)\n",
        "\n",
        "#4.USING MAP FUNCTION\n",
        "#eg:\n",
        "# Define a function to print each element\n",
        "def print_element(element):\n",
        "\tprint(element)\n",
        "my_list = [1, 3, 5, 7, 9]\n",
        "result = map(print_element, my_list)\n",
        "for _ in result:\n",
        "\tpass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC264pngzvX6",
        "outputId": "dba659d6-5c7e-4cb7-9d5e-8d89f01236ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "****************************************************************************************************\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "****************************************************************************************************\n",
            "[1, 4, 9, 16, 25]\n",
            "****************************************************************************************************\n",
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.How do you handle exceptions in Python?"
      ],
      "metadata": {
        "id": "12KawPhM39qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exceptions are used to handle errors and unexpected situations in your code\n",
        "#Here's how to handle exceptions in Python:\n",
        "#1.Try Block: This block contains the code that may raise an exception. You wrap this code inside a try block.\n",
        "\n",
        "#2.Except Block: If an exception is raised in the try block,\n",
        "#  Python looks for an except block that can handle that exception.\n",
        "#  If it finds a matching except block, it executes the code inside that block.\n",
        "\n",
        "#3.ExceptionType: You specify the type of exception that you want to catch in the except block.\n",
        "\n",
        "#eg:\n",
        "try:\n",
        "    num = int(input(\"Enter a number: \"))\n",
        "    result = 10 / num\n",
        "except ZeroDivisionError:\n",
        "    print(\"You can't divide by zero.\")\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid number.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    print(f\"Result is: {result}\")\n",
        "finally:\n",
        "    print(\"Execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckx7mh9g37uf",
        "outputId": "96bdb9a8-0cc0-4980-e18c-8a425e76d657"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a number: 10\n",
            "Result is: 1.0\n",
            "Execution completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What are list comprehensions in Python?"
      ],
      "metadata": {
        "id": "JI8hw4P-55wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List comprehensions in Python are a concise and readable way to create lists.\n",
        "#They provide a compact syntax for generating new lists by applying an expression to\n",
        "#each item in an existing iterable (such as a list, tuple, or string) and optionally filtering the items based on a condition.\n",
        "#syntax:\n",
        "#new_list = [expression for item in iterable if condition]\n",
        "#eg:\n",
        "#1.Creating a List of Squares:\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "squares = [num ** 2 for num in numbers]\n",
        "\n",
        "#eg:\n",
        "#2.Creating a List of Strings in Uppercase:\n",
        "words = [\"apple\", \"banana\", \"cherry\"]\n",
        "uppercase_words = [word.upper() for word in words]\n",
        "\n",
        "#eg:\n",
        "#3.Extracting Initials from Names:\n",
        "names = [\"John Doe\", \"Alice Johnson\", \"Bob Smith\"]\n",
        "initials = [name.split()[0][0] + name.split()[1][0] for name in names]"
      ],
      "metadata": {
        "id": "aKeF964w54-2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is the purpose of the if __name__ == \"__main__\" statement?"
      ],
      "metadata": {
        "id": "rWiN7mXu7coE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The if __name__ == \"__main__\": statement in Python is used to control the execution of code within a script or module.\n",
        "#When a Python file is run as a script, the code within it is executed.\n",
        "#However, when it is imported as a module in another script or program,\n",
        "#the code is also executed unless it's placed within an if __name__ == \"__main__\": block.\n",
        "#This provides better control over code execution and promotes code reusability."
      ],
      "metadata": {
        "id": "zhR7fe-N7cL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is the purpose of the with statement in Python?"
      ],
      "metadata": {
        "id": "rCa4SE5iDY5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The with statement is a valuable tool for improving code quality and ensuring that resources are managed correctly,\n",
        "#making Python code more reliable and readable.\n",
        "#It is used to simplify resource management, particularly for operations that involve acquiring and releasing resources like file handling,\n",
        "#database connections, and network sockets.\n",
        "#It is primarily used with objects that have defined context managers"
      ],
      "metadata": {
        "id": "DEo1aY43Dcpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What are the key features of Spark?"
      ],
      "metadata": {
        "id": "uuosIu6mEWRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apache Spark is a powerful open-source, distributed computing system that is designed for big data processing and analytics.\n",
        "#It offers several key features and advantages, making it a popular choice for various data processing tasks.\n",
        "#Spark can be up to 1000 times faster than Hadoop MapReduce for some workloads.\n",
        "#It provides high-level APIs in multiple programming languages.\n",
        "#It supports various data processing workloads, including batch processing,\n",
        "#real-time streaming, machine learning, graph processing, and interactive queries, all within a single framework\n",
        "#It does parallel Processing"
      ],
      "metadata": {
        "id": "N9zzKxmJEeFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are Resilient Distributed Datasets (RDDs) in Spark?"
      ],
      "metadata": {
        "id": "_KZvmtFyEfc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resilient Distributed Datasets (RDDs) are a fundamental data structure in Apache Spark\n",
        "#RDDs serve as the foundation for higher-level abstractions in Spark, such as DataFrames and Datasets,\n",
        "#which offer optimizations and a more SQL-like query interface.\n",
        "#However, RDDs are still used directly in situations where fine-grained control over distributed data processing is required,\n",
        "#or when you need to work with non-tabular data types like key-value pairs.\n",
        "#This feature ensures data reliability and availability\n",
        "#RDDs are distributed across a cluster of machines, enabling parallel processing of data.\n",
        "#Each RDD is divided into multiple partitions, with each partition stored on a different node in the cluster\n",
        "#RDDs are immutable, which means their data cannot be changed once they are created"
      ],
      "metadata": {
        "id": "lNox8pPkGolX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is the difference between a DataFrame and an RDD in Spark?"
      ],
      "metadata": {
        "id": "L-sb8S9aH9Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrames and Resilient Distributed Datasets (RDDs) are both fundamental data structures in Apache Spark,\n",
        "#but they serve different purposes and have distinct characteristics.\n",
        "\n",
        "#RDD:\n",
        "#It is a lower-level abstraction in Spark. It is a distributed collection of data that can be processed in parallel\n",
        "#It do not have an inherent schema. They can hold unstructured or semi-structured data.\n",
        "#RDDs are available in multiple programming languages, including Scala, Java, Python, and R.\n",
        "#These are low-level, and performance depends on the user's code and optimizations\n",
        "#It can handle structured, semi-structured, or unstructured data, but handling structured data requires more manual effort.\n",
        "\n",
        "#DataFrame:\n",
        "#DataFrame is a higher-level abstraction introduced in Spark that represents data in a tabular form,\n",
        "#similar to a relational database table or a Pandas DataFrame in Python.\n",
        "#It have a schema that defines the structure of the data, including column names and data types.\n",
        "#DataFrames are primarily available in Scala and Python (PySpark), with limited support in Java and R\n",
        "#DataFrames are designed for structured data, and their schema enforces structure and data integrity."
      ],
      "metadata": {
        "id": "PP7JDNkUITjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What is Spark's ecosystem?"
      ],
      "metadata": {
        "id": "qo9qhGmfKR2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apache Spark's ecosystem is a comprehensive set of libraries, tools, and frameworks built around the Spark core engine,\n",
        "#which provides a fast and general-purpose cluster computing system.\n",
        "#Spark's ecosystem extends its capabilities and offers solutions for a wide range of data processing and analytics needs.\n",
        "#This is the foundation of the Spark ecosystem, providing the basic functionality for distributed data processing,\n",
        "#including Resilient Distributed Datasets (RDDs), task scheduling, and fault tolerance."
      ],
      "metadata": {
        "id": "j-svR2PZKQ12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}